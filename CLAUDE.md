# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is an MCP (Model Context Protocol) server that provides advanced AI capabilities including web search and code execution using OpenAI's models. The project exposes a single `iris` tool that accepts natural language queries and can perform web searches, high-precision reasoning, and code execution depending on the specified parameters.

**Current Version: 0.3.0**

## Architecture

- **Single-file TypeScript server** (`src/index.ts`) - Contains the entire MCP server implementation
- **MCP SDK integration** - Uses `@modelcontextprotocol/sdk` for server framework  
- **OpenAI Integration** - Supports both gpt-5 (default) and o3 models with optional code interpreter
- **Environment-based configuration** - Uses env vars for API key and search parameters
- **Dynamic tool construction** - Web search + optional code interpreter based on parameters

## Development Commands

Build the project:
```bash
npm run build
```

The build process compiles TypeScript to JavaScript in the `server/` directory and makes the output executable.

## Key Environment Variables

- `OPENAI_API_KEY` - Required OpenAI API key
- `SEARCH_CONTEXT_SIZE` - Optional: low/medium/high (default: medium)
- `REASONING_EFFORT` - Optional: low/medium/high (default: medium)

## Project Structure

- `src/index.ts` - Main server implementation with iris tool
- `server/` - Compiled JavaScript output (generated by build)
- `manifest.json` - DXT manifest for MCP tool distribution
- `tsconfig.json` - TypeScript configuration with strict settings
- `docs/dev/model-selection-and-code-interpreter/` - Design documentation for v0.3.0 features

## MCP Tool Implementation

The server exposes one tool with advanced capabilities:

### `iris` Tool (v0.3.0)

An AI agent with advanced web search and code execution capabilities. Supports model selection and optional code interpreter for data analysis.

#### Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `input` | string | **required** | Natural language query for search, reasoning, or code tasks |
| `searchContextSize` | enum | `medium` | Web search context size: `low`, `medium`, `high` |
| `reasoningEffort` | enum | `medium` | AI reasoning effort level: `low`, `medium`, `high` |
| `model` | enum | `gpt-5` | AI model selection: `gpt-5`, `o3` |
| `useCodeInterpreter` | boolean | `false` | Enable code execution and data analysis capabilities |

## Usage Scenarios

### 1. Web検索 (従来機能/デフォルト動作)

一般的な情報検索やWeb検索が必要な場合のデフォルト動作:

```typescript
// MCPクライアント側での呼び出し例
{
  "input": "最新のAI技術について教えて"
  // model: "gpt-5" (デフォルト)
  // useCodeInterpreter: false (デフォルト)
}
```

### 2. 高精度な推論が必要な場合

複雑な数学的問題や高度な論理的推論が必要な場合:

```typescript
{
  "input": "複雑な数学的問題の解法を段階的に説明して",
  "model": "o3",
  "reasoningEffort": "high"
}
```

### 3. データ分析・コード実行が必要な場合

CSVデータの処理、グラフ作成、統計分析などが必要な場合:

```typescript
{
  "input": "売上データを分析してトレンドグラフを作成して",
  "useCodeInterpreter": true,
  // model: "gpt-5" (デフォルト - code interpreterとの組み合わせに最適)
}
```

### 4. 高精度推論 + コード実行の組み合わせ

科学的計算や複雑なデータ処理が必要な場合:

```typescript
{
  "input": "物理シミュレーションを実装して結果を可視化して",
  "model": "o3",
  "useCodeInterpreter": true,
  "reasoningEffort": "high"
}
```

## MCPサーバーとしての使用方法

### 1. DXTでのインストール

```bash
# DXT CLIを使用してインストール
dxt install mcp-ai-assistant-iris

# または直接パッケージから
dxt install mokemokechicken/mcp-ai-assistant-iris
```

### 2. Claude Desktop での設定

`claude_desktop_config.json` に追加:

```json
{
  "mcpServers": {
    "mcp-ai-assistant-iris": {
      "command": "npx",
      "args": ["mcp-ai-assistant-iris"],
      "env": {
        "OPENAI_API_KEY": "your-openai-api-key"
      }
    }
  }
}
```

### 3. 環境変数での設定

```bash
export OPENAI_API_KEY="your-openai-api-key"
export SEARCH_CONTEXT_SIZE="medium"  # optional
export REASONING_EFFORT="medium"     # optional
```

## 機能詳細

### モデル選択機能

- **gpt-5** (デフォルト): 一般的な用途に最適、コストパフォーマンスが良い
- **o3**: 高精度な推論が必要な複雑なタスクに適している

### Code Interpreter機能

有効化すると以下が可能:
- Python コードの実行
- データ分析とビジュアライゼーション
- ファイル処理
- 統計計算
- 機械学習モデルの実行

**制約事項:**
- セッション料金: $0.03/session
- 20分のアイドル時間で自動終了
- サンドボックス環境での実行

### エラーハンドリング

- 無効なモデル名の検出
- Code Interpreter実行エラーの適切な処理
- OpenAI APIエラーの詳細メッセージ
- 一般的なエラーの適切な処理

## コスト最適化の指針

1. **一般的な検索**: デフォルト設定 (gpt-5 + web search)
2. **高精度推論が必要**: `model: "o3"` を指定
3. **データ分析が必要**: `useCodeInterpreter: true` を指定
4. **複雑なタスク**: 両方のオプションを組み合わせ

## Versioning

バージョン情報の更新時は以下のファイルを同期して更新:
- `src/index.ts` (line 40)
- `package.json` (version field)
- `manifest.json` (version field)
- `CLAUDE.md` (current version: 0.3.0)